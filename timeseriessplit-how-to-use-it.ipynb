{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Notebook Contents\n\nIn this notebook I'll just show how to use scikit-learn [TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html) class to set up Cross Validation of our models. \n\nThe notebook is divided in 3 simple sections: \n\n0) [CrossValidation Strategies](#crossvalidation_strategies) <br>\n\n1) [TimeSeriesSplit](#timeseriessplit) <br>\n\n2) [Example on Aquifer_Petrignano dataset](#example_on_aquifer_petrignano_dataset) <br>\n\n\n\nPlease look at [this](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py) wonderful page for further theoretical explanations on CV splits. ","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.options.display.max_columns = 30\nimport os\nimport re\nfrom colorama import Fore, Back, Style\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib\nfrom matplotlib.patches import Patch\nfrom matplotlib import pyplot as plt\nplt.rcParams.update({'figure.max_open_warning': 0})\nplt.style.use('fivethirtyeight')\ncmap_data = plt.cm.Paired\ncmap_cv = plt.cm.coolwarm\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-20T01:57:28.836308Z","iopub.execute_input":"2023-09-20T01:57:28.837047Z","iopub.status.idle":"2023-09-20T01:57:30.804009Z","shell.execute_reply.started":"2023-09-20T01:57:28.836996Z","shell.execute_reply":"2023-09-20T01:57:30.803136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function modified from https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html\n\ndef plot_cv_indices(cv, n_splits, X, y, date_col = None):\n    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n    \n    fig, ax = plt.subplots(1, 1, figsize = (11, 7))\n    \n    # Generate the training/testing visualizations for each CV split\n    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n        # Fill in indices with the training/test groups\n        indices = np.array([np.nan] * len(X))\n        indices[tt] = 1\n        indices[tr] = 0\n\n        # Visualize the results\n        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n                   c=indices, marker='_', lw=10, cmap=cmap_cv,\n                   vmin=-.2, vmax=1.2)\n\n\n    # Formatting\n    yticklabels = list(range(n_splits))\n    \n    if date_col is not None:\n        tick_locations  = ax.get_xticks()\n        tick_dates = [\" \"] + date_col.iloc[list(tick_locations[1:-1])].astype(str).tolist() + [\" \"]\n\n        tick_locations_str = [str(int(i)) for i in tick_locations]\n        new_labels = ['\\n\\n'.join(x) for x in zip(list(tick_locations_str), tick_dates) ]\n        ax.set_xticks(tick_locations)\n        ax.set_xticklabels(new_labels)\n    \n    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n           xlabel='Sample index', ylabel=\"CV iteration\",\n           ylim=[n_splits+0.2, -.2])\n    ax.legend([Patch(color=cmap_cv(.8)), Patch(color=cmap_cv(.02))],\n              ['Testing set', 'Training set'], loc=(1.02, .8))\n    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n    \n    ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-20T01:57:57.945503Z","iopub.execute_input":"2023-09-20T01:57:57.945892Z","iopub.status.idle":"2023-09-20T01:57:57.963299Z","shell.execute_reply.started":"2023-09-20T01:57:57.945859Z","shell.execute_reply":"2023-09-20T01:57:57.962077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"crossvalidation_strategies\"></a>\n# 0. CrossValidation Strategies\n\nHere I compare differente crossvalidation strategies, on a toy dataset. ","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0"}},{"cell_type":"code","source":"from sklearn.model_selection import KFold, ShuffleSplit, StratifiedKFold, StratifiedShuffleSplit, TimeSeriesSplit\ncvs = [KFold, ShuffleSplit, StratifiedKFold, StratifiedShuffleSplit, TimeSeriesSplit]\nn_points = 100\nn_splits = 5\nX = np.random.randn(100, 10)\npercentiles_classes = [.1, .3, .6]\ny = np.hstack([[ii] * int(100 * perc) for ii, perc in enumerate(percentiles_classes)])\n\nfor i, cv in enumerate(cvs):\n    this_cv = cv(n_splits=n_splits)\n    plot_cv_indices(this_cv, n_splits, X, y, date_col=None)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-09-20T01:58:22.660730Z","iopub.execute_input":"2023-09-20T01:58:22.661291Z","iopub.status.idle":"2023-09-20T01:58:23.724236Z","shell.execute_reply.started":"2023-09-20T01:58:22.661254Z","shell.execute_reply":"2023-09-20T01:58:23.723171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"timeseriessplit\"></a>\n# 1. TimeSeriesSplit\n\nOf course we don't want to use information into the future to train our models, so we will opt for TimeSeriesSplit, again on the toy dataset defined before.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import TimeSeriesSplit\nn_splits = 5\ntscv = TimeSeriesSplit(n_splits)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T01:59:11.217301Z","iopub.execute_input":"2023-09-20T01:59:11.217763Z","iopub.status.idle":"2023-09-20T01:59:11.222892Z","shell.execute_reply.started":"2023-09-20T01:59:11.217725Z","shell.execute_reply":"2023-09-20T01:59:11.222029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#example taken from https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py\n\nfor fold, (train_index, test_index) in enumerate(tscv.split(X)):\n    print(\"Fold: {}\".format(fold))\n    print(\"TRAIN indices:\", train_index, \"\\n\", \"TEST indices:\", test_index)\n    print(\"\\n\")\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n\n\nplot_cv_indices(tscv,n_splits, X, y)\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-20T01:59:11.710611Z","iopub.execute_input":"2023-09-20T01:59:11.711130Z","iopub.status.idle":"2023-09-20T01:59:11.914558Z","shell.execute_reply.started":"2023-09-20T01:59:11.711092Z","shell.execute_reply":"2023-09-20T01:59:11.913526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.1 ignore old data,with a fixed size data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import TimeSeriesSplit\nn_splits = 5\ntscv = TimeSeriesSplit(n_splits=n_splits,max_train_size=20)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:02:46.795860Z","iopub.execute_input":"2023-09-20T02:02:46.796224Z","iopub.status.idle":"2023-09-20T02:02:46.800860Z","shell.execute_reply.started":"2023-09-20T02:02:46.796194Z","shell.execute_reply":"2023-09-20T02:02:46.799969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n    print(\"Fold: {}\".format(fold))\n    print(\"TRAIN indices:\", train_index, \"\\n\", \"TEST indices:\", test_index)\n    print(\"\\n\")\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n\n\nplot_cv_indices(tscv,n_splits, X, y)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:02:48.109692Z","iopub.execute_input":"2023-09-20T02:02:48.110393Z","iopub.status.idle":"2023-09-20T02:02:48.318882Z","shell.execute_reply.started":"2023-09-20T02:02:48.110345Z","shell.execute_reply":"2023-09-20T02:02:48.317830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"example_on_aquifer_petrignano_dataset\"></a>\n# 2. Example on Aquifer_Petrignano dataset\n\nLet's see an example on one of our datasets in the challenge, Aquifer Petrignano.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/acea-water-prediction/Aquifer_Petrignano.csv')\ndf = df.loc[~df['Date'].isna()]\ndf['Date'] = pd.to_datetime(df['Date'], format = \"%d/%m/%Y\").dt.date\ndf.sort_values('Date', ignore_index = True, inplace = True)\ndisplay(df.sample())\n\ntarget_cols = ['Depth_to_Groundwater_P24', 'Depth_to_Groundwater_P25']\nnon_target_cols = list(set(df.columns) - set(target_cols + ['Date']))\n\nX = df[non_target_cols].fillna(-99).shift(1) # I'll create a random feature matrix\ny = df[target_cols]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tscv = TimeSeriesSplit(n_splits)\nplot_cv_indices(tscv, n_splits, X, y, date_col = df['Date'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hope you'll find this notebook useful, if so please upvote it. \n\nTell me what you think in the comments! ","metadata":{"trusted":true}}]}